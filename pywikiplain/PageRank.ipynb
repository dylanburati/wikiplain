{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4duRjzABB9n"
   },
   "source": [
    "## PageRank on Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4duRjzABB9n"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "1. Download a dump of Wikipedia's articles, named `enwiki-{date_string}-pages-articles-multistream.xml.bz2`\n",
    "2. Download the `enwiki-{date_string}-pages-articles-multistream-index.txt.bz2` file\n",
    "3. Move those files into the same folder, removing the `enwiki-{date_string}` prefix\n",
    "4. Process the `xml.bz2` file into a Parquet file using `wikiplain.load_bz2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import glob\n",
    "import gzip\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import socket\n",
    "import struct\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "from collections import ChainMap, defaultdict, deque\n",
    "from contextlib import asynccontextmanager\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from enum import Enum, auto\n",
    "from functools import lru_cache, partial\n",
    "from urllib.parse import urlencode, urlsplit, quote as urlquote, unquote as urlunquote\n",
    "from typing import Any, Awaitable, Callable, Literal, TypeVar\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import polars as pl\n",
    "import sqlalchemy as sa\n",
    "import scipy.sparse\n",
    "from dotenv import load_dotenv\n",
    "from ipywidgets import interact\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import select, text as sqltext\n",
    "from tqdm.auto import tqdm\n",
    "from arsenal.datastructures.unionfind import UnionFind\n",
    "\n",
    "import wikiplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_fmt_str_lengths(160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRankFiles:\n",
    "    def __init__(self, date_string):\n",
    "        self.date_string = date_string\n",
    "        self.enwiki_dir = f\"{os.environ['ENWIKI_DIR']}/{date_string}\"\n",
    "        self.parquet_dir = os.environ.get('ENWIKI_PARQUET_DIR', self.enwiki_dir)\n",
    "        try:\n",
    "            os.mkdir(f\"{self.enwiki_dir}/pagerank\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "    \n",
    "    @property\n",
    "    def enwiki_parquet_filename(self):\n",
    "        return f\"{self.parquet_dir}/enwiki_{self.date_string}.parquet\"\n",
    "    \n",
    "    @property\n",
    "    def encategories_database_uri(self):\n",
    "        return f\"sqlite:///{self.enwiki_dir}/encategories.db\"\n",
    "\n",
    "    @property\n",
    "    def nub_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/nub.pkl\"\n",
    "    \n",
    "    @property\n",
    "    def id_maps_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/id_maps.pkl\"\n",
    "    \n",
    "    @property\n",
    "    def dense_id_arr_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/dense_id_arr.pkl\"\n",
    "    \n",
    "    @property\n",
    "    def edge_filename_pattern(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/edges_*.pkl\"\n",
    "    \n",
    "    def edge_filenames(self, num_partitions):\n",
    "        return [\n",
    "            f\"{self.enwiki_dir}/pagerank/edges_{i}.pkl\"\n",
    "            for i in range(num_partitions)\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def in_degree_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/in_degree.pkl\"\n",
    "    \n",
    "    @property\n",
    "    def out_degree_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/out_degree.pkl\"\n",
    "    \n",
    "    @property\n",
    "    def dab_array_filename(self):\n",
    "        return f\"{self.enwiki_dir}/pagerank/dab_array.pkl\"\n",
    "    \n",
    "    def adjacency_filename(self, partition):\n",
    "        return f\"{self.enwiki_dir}/pagerank/adjacency_{partition}.npz\"\n",
    "    \n",
    "    def adjacency_filenames(self, num_partitions):\n",
    "        return [self.adjacency_filename(i) for i in range(num_partitions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = PageRankFiles(\"20230301\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4duRjzABB9n"
   },
   "source": [
    "### Find title collisions\n",
    "\n",
    "1. There are some pages with the same title - I think this is caused by pages deleted and recreated while the snapshot is in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqf = pq.ParquetFile(files.enwiki_parquet_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overwritten():\n",
    "    overwritten = set()\n",
    "    timestamp_map = {}\n",
    "    article_ids = {}\n",
    "    pqf_size = 0\n",
    "    for batch in tqdm(pqf.iter_batches(batch_size=100), total=pqf.num_row_groups):\n",
    "        for aid, ns, ttl, tm in zip(batch[\"id\"].to_numpy(), batch[\"ns\"].to_numpy(), batch[\"title\"].to_pylist(), batch[\"timestamp\"].to_pylist()):\n",
    "            pqf_size += 1\n",
    "            if ns != 0:\n",
    "                continue\n",
    "            tm = np.datetime64(tm)\n",
    "            other_id = article_ids.setdefault(ttl, aid)\n",
    "            if other_id != aid:\n",
    "                if (timestamp_map[ttl], other_id) < (tm, aid):\n",
    "                    print(f\"{ttl!r}: {aid} > {other_id}\")\n",
    "                    overwritten.add(other_id)\n",
    "                    article_ids[ttl] = aid\n",
    "                    timestamp_map[ttl] = tm\n",
    "                else:\n",
    "                    print(f\"{ttl!r}: {other_id} > {aid}\")\n",
    "                    overwritten.add(aid)\n",
    "            else:\n",
    "                timestamp_map[ttl] = tm\n",
    "    return overwritten, pqf_size\n",
    "\n",
    "try:\n",
    "    with open(files.nub_filename, \"rb\") as fp:\n",
    "        overwritten, pqf_size = pickle.load(fp)\n",
    "except Exception:\n",
    "    overwritten, pqf_size = get_overwritten()\n",
    "    with open(files.nub_filename, \"wb\") as fp:\n",
    "        pickle.dump((overwritten, pqf_size), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4duRjzABB9n"
   },
   "source": [
    "### Build representation of articles/links as a graph\n",
    "\n",
    "1. Create `id_map` from non-redirecting article titles to node number, and `id_map2` from redirecting article titles to node number\n",
    "2. Use `wikiplain` to extract link titles, and use above maps to convert to (src_id, dest_id) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vec:\n",
    "    def __init__(self, dtype):\n",
    "        self.array = np.ndarray((1024,), dtype=dtype)\n",
    "        self.length = 0\n",
    "    \n",
    "    @property\n",
    "    def capacity(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def append(self, v):\n",
    "        idx = self.length\n",
    "        if idx >= self.capacity:\n",
    "            addsz = max(2, self.capacity)\n",
    "            self.array = np.hstack((self.array, np.zeros((addsz,), dtype=self.array.dtype)))\n",
    "        self.array[idx] = v\n",
    "        self.length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_maps():\n",
    "    redirect_group_map = UnionFind()\n",
    "    id_map = {}\n",
    "    redirect_lst = []\n",
    "    dense_ids = Vec(dtype=np.int64)\n",
    "    for batch in tqdm(pqf.iter_batches(batch_size=100), total=math.ceil(pqf_size // 100)):\n",
    "        for aid, ns, ttl, redir in zip(batch[\"id\"].to_numpy(), batch[\"ns\"].to_numpy(), batch[\"title\"].to_pylist(), batch[\"redirect\"].to_pylist()):\n",
    "            if ns != 0 or aid in overwritten:\n",
    "                continue\n",
    "            if redir is not None:\n",
    "                redirect_group_map.union(ttl, redir)\n",
    "                redirect_lst.append(ttl)\n",
    "            else:\n",
    "                assert ttl not in id_map, f\"Expected unique titles, got second instance of {ttl}\"\n",
    "                dense_ids.append(aid)\n",
    "                id_map[ttl] = len(id_map)\n",
    "    id_map2 = {}\n",
    "    for group in redirect_group_map.classes():\n",
    "        centers = [ttl for ttl in group if ttl in id_map]\n",
    "        if len(centers) == 0:\n",
    "            continue\n",
    "        assert len(centers) == 1, str(centers)\n",
    "        for ttl in group:\n",
    "            if ttl != centers[0]:\n",
    "                id_map2[ttl] = id_map[centers[0]]\n",
    "    return id_map, id_map2, dense_ids.array[:dense_ids.length]\n",
    "\n",
    "try:\n",
    "    with open(files.id_maps_filename, \"rb\") as fp:\n",
    "        id_map, id_map2 = pickle.load(fp)\n",
    "    with open(files.dense_id_arr_filename, \"rb\") as fp:\n",
    "        dense_id_arr = pickle.load(fp)\n",
    "except Exception:\n",
    "    id_map, id_map2, dense_id_arr = get_id_maps()\n",
    "    with open(files.id_maps_filename, \"wb\") as fp:\n",
    "        pickle.dump((id_map, id_map2), fp)\n",
    "    with open(files.dense_id_arr_filename, \"wb\") as fp:\n",
    "        pickle.dump(dense_id_arr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6625358, 10408919)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_map), len(id_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anarchism',\n",
       " 'Albedo',\n",
       " 'A',\n",
       " 'Alabama',\n",
       " 'Achilles',\n",
       " 'Abraham Lincoln',\n",
       " 'Aristotle',\n",
       " 'An American in Paris',\n",
       " 'Academy Award for Best Production Design',\n",
       " 'Academy Awards']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(iter(id_map.keys()), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A11y',\n",
       " 'Digital accessibility',\n",
       " 'Accessible computing',\n",
       " 'Open Accessibility Framework',\n",
       " 'Accessible Computing',\n",
       " 'AccessibleComputing',\n",
       " 'Afghan history',\n",
       " 'Afghanistan history',\n",
       " 'Afghanistan/History',\n",
       " 'Afghan History']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(iter(id_map2.keys()), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54225/1456615976.py:1: DeprecationWarning: `columns` is deprecated as an argument to `__init__`; use `schema` instead.\n",
      "  localsizes = (pl.DataFrame([(id(value), name, sys.getsizeof(value)) for name, value in locals().items()],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>size</th><th>name</th></tr><tr><td>i64</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>140568502228480</td><td>335544408</td><td>[&quot;id_map2&quot;]</td></tr><tr><td>140568502348032</td><td>335544408</td><td>[&quot;id_map&quot;]</td></tr><tr><td>94030689935712</td><td>1859</td><td>[&quot;_i4&quot;]</td></tr><tr><td>94033791202928</td><td>1654</td><td>[&quot;_i9&quot;]</td></tr><tr><td>94033791160288</td><td>1309</td><td>[&quot;_i7&quot;]</td></tr><tr><td>94030649687744</td><td>1072</td><td>[&quot;TypeVar&quot;]</td></tr><tr><td>94030677887280</td><td>1072</td><td>[&quot;tqdm&quot;]</td></tr><tr><td>94030673125936</td><td>1072</td><td>[&quot;_3&quot;]</td></tr><tr><td>94030689909408</td><td>1072</td><td>[&quot;UnionFind&quot;]</td></tr><tr><td>94030649450528</td><td>1072</td><td>[&quot;Enum&quot;]</td></tr><tr><td>94030649530384</td><td>1072</td><td>[&quot;auto&quot;]</td></tr><tr><td>94030649560752</td><td>1072</td><td>[&quot;ChainMap&quot;]</td></tr><tr><td>...</td><td>...</td><td>...</td></tr><tr><td>140569077576848</td><td>144</td><td>[&quot;create_engine&quot;]</td></tr><tr><td>140568514913632</td><td>144</td><td>[&quot;get_id_maps&quot;]</td></tr><tr><td>140569077174848</td><td>144</td><td>[&quot;select&quot;]</td></tr><tr><td>140570553701040</td><td>113</td><td>[&quot;__doc__&quot;]</td></tr><tr><td>140564323909424</td><td>112</td><td>[&quot;dense_id_arr&quot;]</td></tr><tr><td>140568514712992</td><td>100</td><td>[&quot;_i6&quot;]</td></tr><tr><td>140568514716240</td><td>97</td><td>[&quot;_i&quot;, &quot;_i12&quot;]</td></tr><tr><td>140564323993520</td><td>96</td><td>[&quot;_ii&quot;, &quot;_i11&quot;]</td></tr><tr><td>140568514938416</td><td>83</td><td>[&quot;_i3&quot;]</td></tr><tr><td>140568514942256</td><td>82</td><td>[&quot;_i5&quot;]</td></tr><tr><td>140568502264304</td><td>74</td><td>[&quot;_iii&quot;, &quot;_i10&quot;]</td></tr><tr><td>140570573427056</td><td>72</td><td>[&quot;socket&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 3)\n",
       "┌─────────────────┬───────────┬──────────────────┐\n",
       "│ id              ┆ size      ┆ name             │\n",
       "│ ---             ┆ ---       ┆ ---              │\n",
       "│ i64             ┆ i64       ┆ list[str]        │\n",
       "╞═════════════════╪═══════════╪══════════════════╡\n",
       "│ 140568502228480 ┆ 335544408 ┆ [\"id_map2\"]      │\n",
       "│ 140568502348032 ┆ 335544408 ┆ [\"id_map\"]       │\n",
       "│ 94030689935712  ┆ 1859      ┆ [\"_i4\"]          │\n",
       "│ 94033791202928  ┆ 1654      ┆ [\"_i9\"]          │\n",
       "│ ...             ┆ ...       ┆ ...              │\n",
       "│ 140568514938416 ┆ 83        ┆ [\"_i3\"]          │\n",
       "│ 140568514942256 ┆ 82        ┆ [\"_i5\"]          │\n",
       "│ 140568502264304 ┆ 74        ┆ [\"_iii\", \"_i10\"] │\n",
       "│ 140570573427056 ┆ 72        ┆ [\"socket\"]       │\n",
       "└─────────────────┴───────────┴──────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localsizes = (pl.DataFrame([(id(value), name, sys.getsizeof(value)) for name, value in locals().items()],\n",
    "                          columns=['id', 'name', 'size'])\n",
    "              .groupby('id')\n",
    "              .agg(pl.max(\"size\"), pl.col(\"name\").apply(lambda ser: ser.to_list()))\n",
    "              .sort('size', descending=True)\n",
    "              .head(50)\n",
    "             )\n",
    "localsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairVec:\n",
    "    def __init__(self, dtype):\n",
    "        self.array = np.ndarray((1024, 2), dtype=dtype)\n",
    "        self.length = 0\n",
    "    \n",
    "    @property\n",
    "    def capacity(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def append(self, v1, v2):\n",
    "        idx = self.length\n",
    "        if idx >= self.capacity:\n",
    "            addsz = max(2, self.capacity)\n",
    "            self.array = np.vstack((self.array, np.zeros((addsz, 2), dtype=self.array.dtype)))\n",
    "        self.array[idx] = [v1, v2]\n",
    "        self.length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wiki_link(line):\n",
    "    dest_ttl = line.strip()\n",
    "    if len(dest_ttl) == 0:\n",
    "        return None\n",
    "    dest_ttl = dest_ttl[0].upper() + dest_ttl[1:]\n",
    "    dest_ttl = dest_ttl.split('|', maxsplit=1)[0]\n",
    "    dest_ttl = dest_ttl.split('#', maxsplit=1)[0]\n",
    "    return dest_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PARTITION_SIZE = 16\n",
    "PARTITION_SIZE = 1 << LOG_PARTITION_SIZE\n",
    "N = len(id_map)\n",
    "NUM_PARTITIONS = math.ceil(N / PARTITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_id_map = ChainMap(id_map, id_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6625358"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge format\n",
    "\n",
    "- `edges_{n}.pkl` stores the outgoing links from `PARITION_SIZE*n ..< PARTITION_SIZE*(n+1)`\n",
    "- These are stored in a list where element `i` contains the links out to `PARITION_SIZE*i ..< PARTITION_SIZE*(i+1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(iterable, size):\n",
    "    \"\"\"Split an iterable into list chunks of size `n`.\n",
    "    \n",
    "    The last chunk can be fewer than `n` elements long, but it won't be empty.\n",
    "    \"\"\"\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        chunk = list(itertools.islice(iterator, size))\n",
    "        if chunk:\n",
    "            yield chunk\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def lazy_chunk(iterable, n):\n",
    "    \"\"\"Split an iterable into iterable chunks of size `n`.\n",
    "    \n",
    "    The last chunk can be fewer than `n` elements long, but it won't be empty.\n",
    "    \"\"\"\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        try:\n",
    "            first = next(iterator)\n",
    "        except StopIteration:\n",
    "            return\n",
    "        yield itertools.chain([first], itertools.islice(iterator, n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pager(DF, size):\n",
    "    num_pages = math.ceil(DF.shape[0] / size)\n",
    "    page_input = list(range(num_pages)) if num_pages < 1000 else (0, num_pages, 1)\n",
    "    return interact(lambda page: DF.slice(page*size, size), page=page_input)\n",
    "\n",
    "def searcher(DF, columns, page_size):\n",
    "    def searcher_run(q):\n",
    "        mask = (\n",
    "            DF\n",
    "            .select([pl.col(c).str.contains(q) for c in columns])\n",
    "            .max(axis=1)\n",
    "        )\n",
    "        return DF.filter(mask).slice(0, page_size)\n",
    "    return interact(searcher_run, q=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_degree = np.zeros(N, dtype=np.int32)\n",
    "out_degree = np.zeros(N, dtype=np.int32)\n",
    "# article_len_arr = np.zeros(N, dtype=np.int32)\n",
    "def get_edges():\n",
    "    with tqdm(position=1) as progress:\n",
    "        iterator = tqdm(pqf.iter_batches(batch_size=100), total=math.ceil(pqf_size / 100))\n",
    "        iterator = map(\n",
    "            lambda b: zip(\n",
    "                b[\"id\"].to_numpy(),\n",
    "                b[\"ns\"].to_numpy(),\n",
    "                map(operator.attrgetter(\"is_valid\"), b[\"redirect\"]),\n",
    "                b[\"text\"].to_pylist()\n",
    "            ),\n",
    "            iterator\n",
    "        )\n",
    "        iterator = itertools.chain.from_iterable(iterator)\n",
    "        iterator = filter(lambda e: not e[2] and e[1] == 0 and e[0] not in overwritten, iterator)\n",
    "        iterator = enumerate(map(operator.itemgetter(3), iterator))\n",
    "        filenames = files.edge_filenames(NUM_PARTITIONS)\n",
    "        for part_idx, subitr in enumerate(lazy_chunk(iterator, PARTITION_SIZE)):\n",
    "            edges = [PairVec('int32') for _ in range(0, N, PARTITION_SIZE)]\n",
    "            for src_id, text in subitr:\n",
    "                for link in wikiplain.get_links(text):\n",
    "                    dest_ttl = parse_wiki_link(link)\n",
    "                    if (dest_id := id_map.get(dest_ttl) or id_map2.get(dest_ttl)) is not None:\n",
    "                        partition = dest_id >> LOG_PARTITION_SIZE\n",
    "                        edges[partition].append(src_id, dest_id)\n",
    "                        in_degree[dest_id] += 1\n",
    "                        out_degree[src_id] += 1\n",
    "                        progress.update()\n",
    "            with open(filenames[part_idx], \"wb\") as fp:\n",
    "                pickle.dump([vec.array[:vec.length] for vec in edges], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_dab_array():\n",
    "#     result = np.zeros(N, dtype=np.bool8)\n",
    "#     dab_proc = subprocess.Popen(\n",
    "#         [\"wikiplain\", \"--fraction\", \"1\", \"-c\", \"only-dab\", \"--ns\", \"0\", files.enwiki_database_filename],\n",
    "#         stdout=subprocess.PIPE,\n",
    "#         stderr=subprocess.PIPE\n",
    "#     )\n",
    "#     iterator = make_links_iter(dab_proc.stdout)\n",
    "#     iterator = tqdm(iterator, position=0, total=len(id_map))\n",
    "#     iterator = map(lambda pair: (pair[0].decode(\"utf-8\"), pair[1]), iterator)\n",
    "#     for n, subitr in enumerate(lazy_chunk(iterator, PARTITION_SIZE)):\n",
    "#         for ttl, text in subitr:\n",
    "#             src_id = id_map[ttl]\n",
    "#             if len(text) > 0:\n",
    "#                 result[src_id] = True\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDF = pl.scan_parquet(files.enwiki_parquet_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_fnames = glob.glob(files.edge_filename_pattern)\n",
    "try:\n",
    "    assert set(edge_fnames) == set(files.edge_filenames(NUM_PARTITIONS))\n",
    "    for fname in edge_fnames:\n",
    "        with open(fname, \"rb\") as fp:\n",
    "            assert len(pickle.load(fp)) == NUM_PARTITIONS\n",
    "    with open(files.in_degree_filename, \"rb\") as fp:\n",
    "        in_degree = pickle.load(fp)\n",
    "    with open(files.out_degree_filename, \"rb\") as fp:\n",
    "        out_degree = pickle.load(fp)\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "    get_edges()\n",
    "    edge_fnames = glob.glob(files.edge_filename_pattern)\n",
    "    with open(files.in_degree_filename, \"wb\") as fp:\n",
    "        pickle.dump(in_degree, fp)\n",
    "    with open(files.out_degree_filename, \"wb\") as fp:\n",
    "        pickle.dump(out_degree, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open(files.dab_array_filename, \"rb\") as fp:\n",
    "#         dab_array = pickle.load(fp)\n",
    "# except Exception as exc:\n",
    "#     print(exc)\n",
    "#     dab_array = get_dab_array()\n",
    "#     with open(files.dab_array_filename, \"wb\") as fp:\n",
    "#         pickle.dump(dab_array, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adjacency_matrix_slice(partition, progress):\n",
    "    \"\"\"Computes the slice of the adjacency matrix A starting at row p*S and ending before row (p+1)*S\n",
    "    \n",
    "    p=partition, S=PARTITION_SIZE, and A is defined so that\n",
    "    A @ np.eye(N)[i] = v, a probability vector where\n",
    "        v[j] = out-degree(i) > 0 | count((i,j) in E) / out-degree(i)\n",
    "               otherwise         | 0\n",
    "    \"\"\"\n",
    "    origin_row = partition * PARTITION_SIZE\n",
    "    n_rows = min(PARTITION_SIZE, N - origin_row)\n",
    "    index_arrs = []\n",
    "    value_arrs = []\n",
    "    for fname in glob.glob(files.edge_filename_pattern):\n",
    "        with open(fname, \"rb\") as fp:\n",
    "            vec = pickle.load(fp)[partition]\n",
    "        # vec is\n",
    "        #  [[src_id_0, dest_id_0],\n",
    "        #   [src_id_1, dest_id_1],\n",
    "        #   ...\n",
    "        #  ]\n",
    "        # Sort by (src,dest), make unique and get counts\n",
    "        key_arr = (vec[:, 0].astype('int64') << 32) | vec[:, 1]\n",
    "        _, order, count = np.unique(key_arr, return_index=True, return_counts=True)\n",
    "        vec = vec[order]\n",
    "        # Normalize `count` based on (src,)\n",
    "        count = count.astype('float64') / out_degree[vec[:, 0]]\n",
    "        index_arrs.append(vec)\n",
    "        value_arrs.append(count)\n",
    "        progress.update()\n",
    "    index_arr = np.vstack(index_arrs)\n",
    "    matrix_slice = scipy.sparse.csr_array(\n",
    "        (np.hstack(value_arrs), (index_arr[:, 1] - origin_row, index_arr[:, 0])),\n",
    "        shape=(n_rows, N),\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    return matrix_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55a828503264579bacd88ec103af0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm(total=NUM_PARTITIONS**2) as progress:\n",
    "    for partition in range(NUM_PARTITIONS):\n",
    "        adj_matrix = compute_adjacency_matrix_slice(partition, progress)\n",
    "        scipy.sparse.save_npz(files.adjacency_filename(partition), adj_matrix, compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     8,    28,   104,   460,  1466, 25044])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(out_degree, [0, 0.1, 0.5, 0.9, 0.99, 0.999, 1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_out_degree = np.log(out_degree + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_out_degree /= log_out_degree.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WMf5L5VEqZb"
   },
   "source": [
    "### Global PageRank\n",
    "\n",
    "The initial rank is a column vector $\\mathbf{r}$ where $\\mathbf{r}_i = \\frac{1}{N}$\n",
    "\n",
    "The transition matrix $\\mathbf{M}$ is N x N; each column represents a source, and each row represents a destination.\n",
    "$\\mathbf{M}_{ij} = P(\\text{next}=i\\,|\\,\\text{current}=j)$. Each column **must** sum to 1 for the calculation to be stable, so if page $j$ contains no links, it is treated as if it had a link to every page.\n",
    "\n",
    "The power method iteratively computes better ranks: $\\mathbf{r'} = (1 - \\alpha) \\mathbf{M}\\mathbf{r} + \\frac{\\alpha}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized PageRank\n",
    "\n",
    "Personalized PageRank uses a preference vector $\\mathbf{p}$ in place of the uniform $\\frac{1}{N}$ for _teleportation_. Pages with no out-links still use a uniform distribution. The initial rank can be any vector, because of the converging property of the power method (explanation at https://mathworld.wolfram.com/Eigenvector.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WMf5L5VEqZb"
   },
   "source": [
    "### Ending iteration\n",
    "\n",
    "At each iteration, we calculate the [perplexity](https://en.wikipedia.org/wiki/Perplexity) of the PageRank distribution, where perplexity is defined as 2 raised to the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of the PageRank distribution, i.e., $2^{H(PR)}$. The initial guess is at maximum entropy, so the first iteration causes perplexity to decrease. Later iterations may change perplexity in either direction; we stop when the change is below a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "wsL0yQKvKqAC"
   },
   "outputs": [],
   "source": [
    "def perplexity(distribution):\n",
    "    return np.power(2, np.sum(-distribution * np.log2(distribution)))\n",
    "\n",
    "def personalized_page_rank(preference, threshold=1, random_jump_prob=0.15):\n",
    "    current_rank = np.ones(N, dtype=np.float64) / N\n",
    "    next_rank = np.zeros(N, dtype=np.float64)\n",
    "    # iteratively update current_rank\n",
    "    edge_follow_prob = 1 - random_jump_prob\n",
    "    prev_perplexity = float('inf')\n",
    "    current_perplexity = perplexity(current_rank)\n",
    "    current_iter = 0\n",
    "    iter_start = time.time()\n",
    "    print(\"Itr# | ΔPerplexity     | Seconds\")\n",
    "    while abs(prev_perplexity - current_perplexity) > threshold:\n",
    "        current_iter += 1\n",
    "        next_rank[:] = random_jump_prob * preference\n",
    "        # update destinations from non-sink nodes (N x N times N x 1 -> N x 1)\n",
    "        spread_probs = np.vstack([\n",
    "            adjacency_matrix_slice.dot(current_rank[:, np.newaxis])\n",
    "            for adjacency_matrix_slice in map(scipy.sparse.load_npz, files.adjacency_filenames(NUM_PARTITIONS))\n",
    "        ])\n",
    "        next_rank += edge_follow_prob * spread_probs[:, 0]  # make column vector 1-D\n",
    "        # update destinations from sink nodes\n",
    "        next_rank[:] += edge_follow_prob * current_rank[out_degree == 0].sum() / N\n",
    "        # copy `next_rank` values into `current_rank``\n",
    "        current_rank[:] = next_rank\n",
    "        # --\n",
    "        # compute perplexity and progress\n",
    "        prev_perplexity = current_perplexity\n",
    "        current_perplexity = perplexity(current_rank)\n",
    "        next_iter_start = time.time()\n",
    "        print(\"{:<3d}    {:<15.6f}   {:.3f}\".format(current_iter,\n",
    "                                                    current_perplexity - prev_perplexity,\n",
    "                                                    next_iter_start - iter_start))\n",
    "        iter_start = next_iter_start\n",
    "    df = pl.DataFrame({\n",
    "        \"title\": id_map.keys(), \"value\": next_rank, \"in_deg\": in_degree, \"out_deg\": out_degree,\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wsL0yQKvKqAC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itr# | ΔPerplexity     | Seconds\n",
      "1      -6590087.373375   41.637\n",
      "2      -18066.651574     32.785\n",
      "3      -7991.425620      31.674\n",
      "4      -3135.253593      30.739\n",
      "5      -1614.272158      13.630\n",
      "6      -903.522792       6.233\n",
      "7      -552.961068       5.260\n",
      "8      -355.355849       3.696\n",
      "9      -238.212649       4.155\n",
      "10     -164.180308       4.471\n",
      "11     -115.689300       4.014\n",
      "12     -82.804801        4.218\n",
      "13     -59.988596        4.146\n",
      "14     -43.842793        3.895\n",
      "15     -32.258310        3.761\n",
      "16     -23.852399        4.413\n",
      "17     -17.703208        3.900\n",
      "18     -13.175938        4.191\n",
      "19     -9.827130         3.918\n",
      "20     -7.340991         3.844\n",
      "21     -5.490338         3.616\n",
      "22     -4.109888         4.532\n",
      "23     -3.078600         3.718\n",
      "24     -2.307258         3.636\n",
      "25     -1.729838         3.504\n",
      "26     -1.297300         3.531\n",
      "27     -0.973129         3.804\n"
     ]
    }
   ],
   "source": [
    "# Run until perplexity changes by less than 1\n",
    "PR = personalized_page_rank(log_out_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_sorted = PR.sort('value', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8f57ff9ff84251851eef1269a2df41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='page', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.pager.<locals>.<lambda>(page)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pager(PR_sorted.slice(0, 2000), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69961da7f32484eb990d776edc486fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='q'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.searcher.<locals>.searcher_run(q)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher(\n",
    "    PR_sorted.slice(0, 200000).with_columns(pl.Series(\"rank\", range(200000))).select([\"rank\", *PR_sorted.columns]),\n",
    "    ['title'],\n",
    "    20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_words = set()\n",
    "upper_words = set()\n",
    "with open(\"debian-american-english-insane.txt\", \"r\") as fp:\n",
    "    for w in map(str.rstrip, fp.readlines()):\n",
    "        if len(w) == 0:\n",
    "            continue\n",
    "        if w.islower():\n",
    "            real_words.add(w)\n",
    "        else:\n",
    "            upper_words.add(w.lower())\n",
    "real_words.difference_update(upper_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_value = PR.loc[:, \"value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_iterators(*iterables, key):\n",
    "    iterators = [iter(x) for x in iterables]\n",
    "    n_open = len(iterators)\n",
    "    is_open = [True for _ in iterators]\n",
    "    heads = [None for _ in iterators]\n",
    "    pred_is_open = pipe_through(operator.itemgetter(0), is_open.__getitem__)\n",
    "    for idx, itr in enumerate(iterators):\n",
    "        try:\n",
    "            heads[idx] = next(itr)\n",
    "        except StopIteration:\n",
    "            n_open -= 1\n",
    "            is_open[idx] = False\n",
    "    while n_open > 0:\n",
    "        idx, min_val = min(filter(pred_is_open, enumerate(heads)), key=lambda p: key(p[1]))\n",
    "        yield min_val\n",
    "        try:\n",
    "            heads[idx] = next(iterators[idx])\n",
    "        except StopIteration:\n",
    "            n_open -= 1\n",
    "            is_open[idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundedIter:\n",
    "    def __init__(self, iterator, stop):\n",
    "        self.iterator = iterator\n",
    "        self.curr = 0\n",
    "        self.stop = stop\n",
    "    \n",
    "    @classmethod\n",
    "    def items(cls, mapping, use_tqdm=False):\n",
    "        total = len(mapping)\n",
    "        iterator = iter(tqdm(mapping.items(), total=total)) if use_tqdm else iter(mapping.items())\n",
    "        return cls(iterator, total)\n",
    "    \n",
    "    @classmethod\n",
    "    def items_by_value_asc(cls, *mappings, use_tqdm=False):\n",
    "        total = sum(len(e) for e in mappings)\n",
    "        iterator = merge_iterators(*(e.items() for e in mappings), key=operator.itemgetter(1))\n",
    "        if use_tqdm:\n",
    "            iterator = iter(tqdm(iterator, total=total))\n",
    "        return cls(iterator, total)\n",
    "    \n",
    "    def get(self, default=None):\n",
    "        if self.curr >= self.stop:\n",
    "            return default, False\n",
    "        self.curr += 1\n",
    "        return next(self.iterator), True\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, _1, _2, _3):\n",
    "        try:\n",
    "            next(self.iterator)\n",
    "        except StopIteration:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anarchism', 0),\n",
       " ('Albedo', 1),\n",
       " ('A', 2),\n",
       " ('Alabama', 3),\n",
       " ('Achilles', 4),\n",
       " ('Abraham Lincoln', 5),\n",
       " ('Aristotle', 6),\n",
       " ('An American in Paris', 7),\n",
       " ('Academy Award for Best Production Design', 8),\n",
       " ('Academy Awards', 9)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(id_map.items(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440055"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dab_array.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def load_adjacency_slice(partition):\n",
    "    return scipy.sparse.load_npz(files.adjacency_filenames(NUM_PARTITIONS)[partition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>in_deg</th>\n",
       "      <th>out_deg</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>2.627924e-08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23005</th>\n",
       "      <td>2.221949e-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23911</th>\n",
       "      <td>2.721998e-08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136013</th>\n",
       "      <td>2.407886e-08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>E6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162896</th>\n",
       "      <td>1.762343e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>T33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785598</th>\n",
       "      <td>1.903712e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>T32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852693</th>\n",
       "      <td>1.516573e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Route 67 (disambiguation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852698</th>\n",
       "      <td>1.421268e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Route 82 (disambiguation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158757</th>\n",
       "      <td>2.198999e-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>222 (disambiguation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167801</th>\n",
       "      <td>2.209949e-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>468 (disambiguation)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                value  in_deg  out_deg                      title\n",
       "number                                                           \n",
       "4715     2.627924e-08     8.0    120.0                         E2\n",
       "23005    2.221949e-08     4.0     54.0                         D6\n",
       "23911    2.721998e-08     6.0    129.0                         E1\n",
       "136013   2.407886e-08     6.0     73.0                         E6\n",
       "162896   1.762343e-08     0.0     14.0                        T33\n",
       "...               ...     ...      ...                        ...\n",
       "4785598  1.903712e-08     0.0     16.0                        T32\n",
       "4852693  1.516573e-08     0.0      8.0  Route 67 (disambiguation)\n",
       "4852698  1.421268e-08     0.0      6.0  Route 82 (disambiguation)\n",
       "5158757  2.198999e-08     2.0     44.0       222 (disambiguation)\n",
       "6167801  2.209949e-08     4.0     36.0       468 (disambiguation)\n",
       "\n",
       "[82 rows x 4 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_ex = id_map[\"List of bus routes in London\"]\n",
    "PR_sorted.loc[np.nonzero(load_adjacency_slice(aid_ex >> LOG_PARTITION_SIZE)[aid_ex % PARTITION_SIZE].multiply(dab_array))[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f14b8c8bf4fc4b1d5b72811153a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16666960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11591, '[\"phoenix\"]', 25008, '5.62075e-06', 1)\n",
      "(85417, '[\"melrose\"]', 25008, '5.62075e-06', 1)\n",
      "(281448, '[\"kcac\"]', 25008, '5.62075e-06', 1)\n",
      "(449299, '[\"fengcheng\"]', 25008, '5.62075e-06', 1)\n",
      "(467388, '[\"paradise\", \"valley\"]', 25008, '5.62075e-06', 1)\n",
      "(480368, '[\"phx\"]', 25008, '5.62075e-06', 1)\n",
      "(548989, '[\"5\", \"cs\"]', 25008, '5.62075e-06', 1)\n",
      "(828246, '[\"inner\", \"loop\"]', 25008, '5.62075e-06', 1)\n",
      "(1044917, '[\"sunnyslope\"]', 25008, '5.62075e-06', 1)\n",
      "(1123471, '[\"arizona\", \"serial\", \"killer\"]', 25008, '5.62075e-06', 1)\n",
      "(1158714, '[\"list\", \"of\", \"streets\", \"named\", \"after\", \"martin\", \"luther\", \"king\", \"jr\"]', 25008, '5.62075e-06', 1)\n",
      "(1540670, '[\"maricopa\", \"freeway\"]', 25008, '5.62075e-06', 1)\n",
      "(1546743, '[\"good\", \"samaritan\", \"hospital\"]', 25008, '5.62075e-06', 1)\n",
      "(1681923, '[\"dobbins\", \"creek\"]', 25008, '5.62075e-06', 1)\n",
      "(1991985, '[\"phoenix\", \"airport\"]', 25008, '5.62075e-06', 1)\n",
      "(2052582, '[\"kool\", \"fm\"]', 25008, '5.62075e-06', 1)\n",
      "(2140249, '[\"gateway\", \"airport\"]', 25008, '5.62075e-06', 1)\n",
      "(2775847, '[\"sports\", \"teams\", \"named\", \"trojans\"]', 25008, '5.62075e-06', 1)\n",
      "(3218424, '[\"spectrum\", \"mall\"]', 25008, '5.62075e-06', 1)\n",
      "(3233367, '[\"kdif\"]', 25008, '5.62075e-06', 1)\n",
      "(3338675, '[\"list\", \"of\", \"periodicals\", \"named\", \"phoenix\"]', 25008, '5.62075e-06', 1)\n",
      "(3338686, '[\"list\", \"of\", \"places\", \"named\", \"for\", \"the\", \"phoenix\"]', 25008, '5.62075e-06', 1)\n",
      "(3647391, '[\"phoenician\"]', 25008, '5.62075e-06', 1)\n",
      "(4068055, '[\"deal\", \"surname\"]', 25008, '5.62075e-06', 1)\n",
      "(4810916, '[\"academy\", \"of\", \"performing\", \"arts\"]', 25008, '5.62075e-06', 1)\n",
      "(6269278, '[\"phoenix\", \"bypass\", \"route\"]', 25008, '5.62075e-06', 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/media/dylan/easystore/caps/data/enwiki/pagerank/keywords.tsv'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with BoundedIter.items_by_value_asc(id_map, id_map2, use_tqdm=True) as combined_id_map_itr:\n",
    "    iter_open = True\n",
    "    flip_flop = (0, 1)\n",
    "    with open(f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[1]}.tsv\", \"w\"):\n",
    "        pass\n",
    "    while iter_open:\n",
    "        phrase_article_lst = []\n",
    "        while iter_open and len(phrase_article_lst) < 5_000_000:\n",
    "            (ttl, aid), iter_open = combined_id_map_itr.get(default=(\"\",0))\n",
    "            special = 2 if \"(disambiguation)\" in ttl else 0\n",
    "            ttld = ttl.replace(\"(disambiguation)\", \"\").strip()\n",
    "            words = getWords(ttld.lower().replace(\"'\", \"+\").replace(\"&\", \"+\"))\n",
    "            if len(words) == 0:\n",
    "                continue\n",
    "            if len(words) == 1 and len(words[0]) <= 2:\n",
    "                continue\n",
    "            if ttl in id_map2:\n",
    "                if ttld[0] == ttld[-1] and not ttld[0].isalnum():\n",
    "                    continue\n",
    "                if len(words) == 1:\n",
    "                    if ttld.endswith(\".\") or ttld.startswith(\".\"):\n",
    "                        continue\n",
    "                    if ttld.isupper():\n",
    "                        orig = PR['title'].values[id_map2[ttl]]\n",
    "                        if len(ttld) <= len(getWords(orig)):\n",
    "                            continue\n",
    "            phrase_article_lst.append((json.dumps(words), aid, \"{:.6g}\".format(PR_value[aid]), special))\n",
    "            partition = aid >> LOG_PARTITION_SIZE\n",
    "            adj = load_adjacency_slice(partition)\n",
    "            inlinks = adj[aid % PARTITION_SIZE]\n",
    "            # elementwise multiply() call, because sparse arrays make `*` matrix-multiplication\n",
    "            # nonzero returns (dim_0_indices, dim_1_indices). inlinks is 1 x N (sparse matrices can't be indexed to vectors)\n",
    "            if ttl in id_map:\n",
    "                for aid2 in np.nonzero(inlinks.multiply(dab_array))[1]:\n",
    "                    ttl2 = PR['title'].values[aid2]\n",
    "                    ttl2 = ttl2.replace(\"(disambiguation)\", \"\")\n",
    "                    words = getWords(ttl2.lower().replace(\"'\", \"+\").replace(\"&\", \"+\"))\n",
    "                    if aid == aid_ex:\n",
    "                        print((aid2, json.dumps(words), aid, \"{:.6g}\".format(PR_value[aid]), special | 1))\n",
    "                    phrase_article_lst.append((json.dumps(words), aid, \"{:.6g}\".format(PR_value[aid]), special | 1))\n",
    "            # if len(words) > 1:\n",
    "            #     for w in words:\n",
    "            #         if len(w) > 2 and w not in real_words:\n",
    "            #             phrase_article_lst.append((json.dumps([w]), aid, \"{:.6g}\".format(PR_value[aid]), special | 1))\n",
    "        if len(phrase_article_lst) == 0:\n",
    "            break\n",
    "        phrase_article_lst.sort(key=operator.itemgetter(0))\n",
    "        with open(f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[0]}.tsv\", \"w\") as wfile:\n",
    "            with open(f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[1]}.tsv\", \"r\") as rfile:\n",
    "                liter = map(lambda row: \"\\t\".join(str(v) for v in row) + \"\\n\", phrase_article_lst)\n",
    "                riter = iter(rfile.readline, \"\")\n",
    "                for row_str in merge_iterators(liter, riter, key=lambda x: x):\n",
    "                    wfile.write(row_str)\n",
    "        flip_flop = flip_flop[::-1]\n",
    "shutil.move(f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[1]}.tsv\", f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[0]}.tsv\")\n",
    "shutil.move(f\"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords_{flip_flop[0]}.tsv\", \"/media/dylan/easystore/caps/data/enwiki/pagerank/keywords.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylan/Documents/datagame.live/datasets/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.anc.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/dylan/Documents/datagame.live/datasets/helpers.py:94: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  result = transform(result)\n"
     ]
    }
   ],
   "source": [
    "one_word_freq = apply_chain(\n",
    "    requests.get('https://www.anc.org/SecondRelease/data/ANC-token-count.txt', verify=False).text,\n",
    "    io.StringIO,\n",
    "    partial(pd.read_csv, sep='\\t', skipfooter=1, header=None, index_col=0, keep_default_na=False),\n",
    "    lambda df: dict(df.iloc[:,[1]].itertuples())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140375909186720</th>\n",
       "      <td>838447930</td>\n",
       "      <td>[PR_sorted2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140375909185712</th>\n",
       "      <td>832810727</td>\n",
       "      <td>[PR_sorted3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140373426495040</th>\n",
       "      <td>733991546</td>\n",
       "      <td>[PR_sorted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140375848156560</th>\n",
       "      <td>681763482</td>\n",
       "      <td>[PR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140372850353216</th>\n",
       "      <td>335544408</td>\n",
       "      <td>[id_map2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140379328004544</th>\n",
       "      <td>335544408</td>\n",
       "      <td>[id_map]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140373163787136</th>\n",
       "      <td>126856312</td>\n",
       "      <td>[query_weight_offsets]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140374438396736</th>\n",
       "      <td>126856312</td>\n",
       "      <td>[query_answers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140376339482160</th>\n",
       "      <td>52228304</td>\n",
       "      <td>[article_query_count]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140373887805904</th>\n",
       "      <td>52228304</td>\n",
       "      <td>[article_extscores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140373380161264</th>\n",
       "      <td>52228304</td>\n",
       "      <td>[article_extcount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877194834672</th>\n",
       "      <td>30890495</td>\n",
       "      <td>[resp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140377832645216</th>\n",
       "      <td>16777432</td>\n",
       "      <td>[real_words]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140375522677824</th>\n",
       "      <td>10485856</td>\n",
       "      <td>[one_word_freq]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140376339481488</th>\n",
       "      <td>6528636</td>\n",
       "      <td>[dab_array]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140377832644768</th>\n",
       "      <td>4194520</td>\n",
       "      <td>[upper_words]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140375434625664</th>\n",
       "      <td>3704280</td>\n",
       "      <td>[phrase_article_lst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140375909497984</th>\n",
       "      <td>9312</td>\n",
       "      <td>[meta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877019612448</th>\n",
       "      <td>5854</td>\n",
       "      <td>[_i28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877261328800</th>\n",
       "      <td>4066</td>\n",
       "      <td>[_i111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877088075504</th>\n",
       "      <td>4066</td>\n",
       "      <td>[_i156]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877272197680</th>\n",
       "      <td>4062</td>\n",
       "      <td>[_i104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877261384080</th>\n",
       "      <td>4012</td>\n",
       "      <td>[_i103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877283262352</th>\n",
       "      <td>4008</td>\n",
       "      <td>[_i100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877075953744</th>\n",
       "      <td>4008</td>\n",
       "      <td>[_i102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877270384192</th>\n",
       "      <td>3579</td>\n",
       "      <td>[_i176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877270391232</th>\n",
       "      <td>3571</td>\n",
       "      <td>[_i181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877105374400</th>\n",
       "      <td>3567</td>\n",
       "      <td>[_i180]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877091439600</th>\n",
       "      <td>3162</td>\n",
       "      <td>[_i36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877257099600</th>\n",
       "      <td>2559</td>\n",
       "      <td>[piece]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877232751456</th>\n",
       "      <td>1898</td>\n",
       "      <td>[_i45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877046021024</th>\n",
       "      <td>1786</td>\n",
       "      <td>[_i2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140381173308544</th>\n",
       "      <td>1656</td>\n",
       "      <td>[_ih, In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877088034672</th>\n",
       "      <td>1623</td>\n",
       "      <td>[_i157]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877225734640</th>\n",
       "      <td>1623</td>\n",
       "      <td>[_iii, _i182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877181208160</th>\n",
       "      <td>1623</td>\n",
       "      <td>[_i146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877061969456</th>\n",
       "      <td>1569</td>\n",
       "      <td>[_i140]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877272240368</th>\n",
       "      <td>1558</td>\n",
       "      <td>[_i137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877046254112</th>\n",
       "      <td>1491</td>\n",
       "      <td>[_i16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877046117824</th>\n",
       "      <td>1226</td>\n",
       "      <td>[_i6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877088222624</th>\n",
       "      <td>1177</td>\n",
       "      <td>[_i112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877105449136</th>\n",
       "      <td>1177</td>\n",
       "      <td>[_i37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877094793104</th>\n",
       "      <td>1134</td>\n",
       "      <td>[_i73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877018793392</th>\n",
       "      <td>1123</td>\n",
       "      <td>[_i1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877232742960</th>\n",
       "      <td>1109</td>\n",
       "      <td>[_i101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877232787536</th>\n",
       "      <td>1103</td>\n",
       "      <td>[_i72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877007181728</th>\n",
       "      <td>1072</td>\n",
       "      <td>[auto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877007149200</th>\n",
       "      <td>1072</td>\n",
       "      <td>[Enum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877232792752</th>\n",
       "      <td>1072</td>\n",
       "      <td>[PageRankFiles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94877007212096</th>\n",
       "      <td>1072</td>\n",
       "      <td>[ChainMap]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      size                    name\n",
       "id                                                \n",
       "140375909186720  838447930            [PR_sorted2]\n",
       "140375909185712  832810727            [PR_sorted3]\n",
       "140373426495040  733991546             [PR_sorted]\n",
       "140375848156560  681763482                    [PR]\n",
       "140372850353216  335544408               [id_map2]\n",
       "140379328004544  335544408                [id_map]\n",
       "140373163787136  126856312  [query_weight_offsets]\n",
       "140374438396736  126856312         [query_answers]\n",
       "140376339482160   52228304   [article_query_count]\n",
       "140373887805904   52228304     [article_extscores]\n",
       "140373380161264   52228304      [article_extcount]\n",
       "94877194834672    30890495                  [resp]\n",
       "140377832645216   16777432            [real_words]\n",
       "140375522677824   10485856         [one_word_freq]\n",
       "140376339481488    6528636             [dab_array]\n",
       "140377832644768    4194520           [upper_words]\n",
       "140375434625664    3704280    [phrase_article_lst]\n",
       "140375909497984       9312                  [meta]\n",
       "94877019612448        5854                  [_i28]\n",
       "94877261328800        4066                 [_i111]\n",
       "94877088075504        4066                 [_i156]\n",
       "94877272197680        4062                 [_i104]\n",
       "94877261384080        4012                 [_i103]\n",
       "94877283262352        4008                 [_i100]\n",
       "94877075953744        4008                 [_i102]\n",
       "94877270384192        3579                 [_i176]\n",
       "94877270391232        3571                 [_i181]\n",
       "94877105374400        3567                 [_i180]\n",
       "94877091439600        3162                  [_i36]\n",
       "94877257099600        2559                 [piece]\n",
       "94877232751456        1898                  [_i45]\n",
       "94877046021024        1786                   [_i2]\n",
       "140381173308544       1656               [_ih, In]\n",
       "94877088034672        1623                 [_i157]\n",
       "94877225734640        1623           [_iii, _i182]\n",
       "94877181208160        1623                 [_i146]\n",
       "94877061969456        1569                 [_i140]\n",
       "94877272240368        1558                 [_i137]\n",
       "94877046254112        1491                  [_i16]\n",
       "94877046117824        1226                   [_i6]\n",
       "94877088222624        1177                 [_i112]\n",
       "94877105449136        1177                  [_i37]\n",
       "94877094793104        1134                  [_i73]\n",
       "94877018793392        1123                   [_i1]\n",
       "94877232742960        1109                 [_i101]\n",
       "94877232787536        1103                  [_i72]\n",
       "94877007181728        1072                  [auto]\n",
       "94877007149200        1072                  [Enum]\n",
       "94877232792752        1072         [PageRankFiles]\n",
       "94877007212096        1072              [ChainMap]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localsizes = (pd.DataFrame([(id(value), name, sys.getsizeof(value)) for name, value in locals().items()],\n",
    "                          columns=['id', 'name', 'size'])\n",
    "              .groupby('id')\n",
    "              .agg({'size': 'max', 'name': lambda ser: ser.to_list()})\n",
    "              .sort_values('size', ascending=False)\n",
    "              .head(50)\n",
    "             )\n",
    "localsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd71bc8c76b48b39ff3f8cde06d6a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_weight_offsets = []\n",
    "query_weights = Vec(dtype=\"i4, f4\")\n",
    "article_query_count = np.zeros(N, dtype=int)\n",
    "with open(f\"{files.enwiki_dir}/pagerank/keywords.tsv\", \"r\", encoding=\"utf-8\") as rfile:\n",
    "    with open(f\"{files.enwiki_dir}/wikiwords.json\", \"w\", encoding=\"utf-8\") as wfile:\n",
    "        wfile.write(\"[\")\n",
    "        itr = map(lambda s: s.split(\"\\t\"), tqdm(rfile))\n",
    "        for el, group in itertools.groupby(itr, key=operator.itemgetter(0)):\n",
    "            meta = {}\n",
    "            for query_s, aid_s, pr_s, special_s in group:\n",
    "                query = json.loads(query_s)\n",
    "                aid = int(aid_s)\n",
    "                pr = float(pr_s)\n",
    "                special = int(special_s)\n",
    "                pr_norm = (pr * 1e6)**2\n",
    "                score = [1, 0.5, 0.2, 0.1][special]\n",
    "                if len(query) <= 2:\n",
    "                    prob = np.product([one_word_freq.get(w, 0) for w in query])\n",
    "                    score *= (1e-7 / max(1e-7, prob)) ** 0.5\n",
    "                meta.setdefault(aid, (pr_norm, score))\n",
    "                if pr_norm * score > meta[aid][0] * meta[aid][1]:\n",
    "                    meta[aid] = (pr_norm, score)\n",
    "            query_weight_offsets.append(query_weights.length)\n",
    "            total_pr = sum(v1 for v1, _ in meta.values())\n",
    "            for aid, (v1, v2) in meta.items():\n",
    "                query_weights.append((aid, v1 * v2 / total_pr))\n",
    "                article_query_count[aid] += 1\n",
    "            if len(query_weight_offsets) > 1:\n",
    "                wfile.write(\",\")\n",
    "            wfile.write(el)\n",
    "        wfile.write(\"]\")\n",
    "        query_weight_offsets.append(query_weights.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCHER_CLI_PORT = 11111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7950f45a724fb5b643f625d7c6592d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as conn:\n",
    "    # conn.setsockopt()\n",
    "    conn.connect(('127.0.0.1', SEARCHER_CLI_PORT))\n",
    "    wr = conn.makefile(mode='w', encoding=\"utf-8\")\n",
    "    total = os.stat(f\"{files.enwiki_dir}/wikiwords.json\").st_size\n",
    "    conn.send(struct.pack(\">I\", total))\n",
    "    with tqdm.wrapattr(open(f\"{files.enwiki_dir}/wikiwords.json\", \"rb\"), \"read\") as fp:\n",
    "        while True:\n",
    "            chunk = fp.read(131072)\n",
    "            if not chunk:\n",
    "                break\n",
    "            conn.send(chunk)\n",
    "    # conn.shutdown(socket.SHUT_WR)\n",
    "    resp = b''\n",
    "    piece = conn.recv(4096)\n",
    "    while piece:\n",
    "        resp += piece\n",
    "        if piece.endswith(b'\\n'):\n",
    "            break\n",
    "        piece = conn.recv(4096)\n",
    "    query_answers = json.loads(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_extscores = np.zeros(N, dtype=np.float64)\n",
    "article_extcount = np.zeros(N, dtype=int)\n",
    "for st, en, v in zip(query_weight_offsets, query_weight_offsets[1:], query_answers):\n",
    "    for aid, weight in query_weights.array[st:en]:\n",
    "        article_extscores[aid] += v * weight\n",
    "        article_extcount[aid] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04134e6c0b9e42769b47f87f823e0530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='p', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function nbhelpers.pager.<locals>.<lambda>(p)>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR_sorted2 = (PR.assign(title=list(id_map.keys()), extscore=article_extscores, extcount=article_extcount)\n",
    "              .sort_values(\"extscore\", ascending=False))\n",
    "pager(PR_sorted2.iloc[:2000], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31840734"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_weights.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da27b8c7b67c48f49369efc9bab30921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='q'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function nbhelpers.searcher.<locals>.searcher_run(q)>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher(PR_sorted2.iloc[:200000].reset_index(drop=True), 'title', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itr# | ΔPerplexity     | Seconds\n",
      "1      -6525347.388890   39.314\n",
      "2      -2842.834844      15.478\n",
      "3      -214.461130       15.371\n",
      "4      -42.215317        11.194\n",
      "5      -13.093852        4.275\n",
      "6      -4.833981         5.181\n",
      "7      -1.927023         6.612\n",
      "8      -0.791616         7.226\n"
     ]
    }
   ],
   "source": [
    "article_extscores_n = article_extscores ** 0.25\n",
    "PPR = personalized_page_rank(article_extscores_n / article_extscores_n.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPR_sorted = PPR.assign(title=list(id_map.keys())).sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a758c256984c4eb654bb50d5d91112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='p', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function nbhelpers.pager.<locals>.<lambda>(p)>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pager(PPR_sorted.iloc[:2000], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = pd.read_csv('people__gameppl.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = people_df.assign(article_id=people_df['original'].apply(combined_id_map.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>article_id</th>\n",
       "      <th>total_views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>escaped</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>968234</td>\n",
       "      <td>612086318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elizabeth ii</th>\n",
       "      <td>Elizabeth II</td>\n",
       "      <td>1676170</td>\n",
       "      <td>123587458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon musk</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>301338</td>\n",
       "      <td>98882645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cristiano ronaldo</th>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>236516</td>\n",
       "      <td>87726046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barack obama</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>211964</td>\n",
       "      <td>86718357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dane dehaan</th>\n",
       "      <td>Dane DeHaan</td>\n",
       "      <td>3290933</td>\n",
       "      <td>6007290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atticus shaffer</th>\n",
       "      <td>Atticus Shaffer</td>\n",
       "      <td>2860826</td>\n",
       "      <td>6002764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sam harris</th>\n",
       "      <td>Sam Harris</td>\n",
       "      <td>608251</td>\n",
       "      <td>6002712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danny mcbride</th>\n",
       "      <td>Danny McBride</td>\n",
       "      <td>1735895</td>\n",
       "      <td>6001988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milkha singh</th>\n",
       "      <td>Milkha Singh</td>\n",
       "      <td>2413482</td>\n",
       "      <td>6001673.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            original  article_id  total_views\n",
       "escaped                                                      \n",
       "donald trump            Donald Trump      968234  612086318.0\n",
       "elizabeth ii            Elizabeth II     1676170  123587458.0\n",
       "elon musk                  Elon Musk      301338   98882645.0\n",
       "cristiano ronaldo  Cristiano Ronaldo      236516   87726046.0\n",
       "barack obama            Barack Obama      211964   86718357.0\n",
       "...                              ...         ...          ...\n",
       "dane dehaan              Dane DeHaan     3290933    6007290.0\n",
       "atticus shaffer      Atticus Shaffer     2860826    6002764.0\n",
       "sam harris                Sam Harris      608251    6002712.0\n",
       "danny mcbride          Danny McBride     1735895    6001988.0\n",
       "milkha singh            Milkha Singh     2413482    6001673.0\n",
       "\n",
       "[3341 rows x 3 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df[['original', 'article_id', 'total_views']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(ids, n):\n",
    "    df = PPR_sorted.iloc[:n]\n",
    "    relevant = df.index.isin(ids)\n",
    "    precision = relevant.mean()\n",
    "    recall = relevant.sum() / len(ids)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00826, 0.9889254714157438)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(people_df['article_id'], 400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7000752e4c43aaa1f1c659735ecfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='p', options=(0, 1), value=0), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function nbhelpers.pager.<locals>.<lambda>(p)>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pager(people_df[~people_df['article_id'].isin(PPR_sorted.iloc[:400000].index)], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPR_sorted.to_csv(f'{files.enwiki_dir}/pagerank/ppr-20220720.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392b7baf8fa34b00b8d85c40977d538c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='q'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.search_ppr(q)>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_ppr(q):\n",
    "    ql = [s for s in q.split(\"|\") if len(s)]\n",
    "    result = [unwrap_apply(id_map.get(k), PPR_sorted.index.get_loc) for k in ql]\n",
    "    return pd.Series(result, index=ql, dtype=np.float64).sort_values()\n",
    "\n",
    "interact(search_ppr, q=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine2 = create_engine(files.encategories_database_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Eddie Fisher' in set(PR_sorted['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_arr = np.array(list(id_map.values()))\n",
    "id_arr == np.array(range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        1,        2, ..., 11593659, 11593660, 11593661])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_arr"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNw97vMeu3UGKrk6j3TYQO8",
   "include_colab_link": true,
   "name": "PageRank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
